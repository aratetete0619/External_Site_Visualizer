## 🌐概要: 
このプロジェクトは、ユーザーがさまざまな関連性を視覚的に探求できるアプリケーションを構築します。ユーザーの検索に基づいて、映画やドラマのキャラクター間の関係図、ウェブサイトの外部リンク、芸能人の交流、あるいはテクノロジー間の結びつきといった「つながり」を視覚化します。ユーザーは、この関係図を直感的に操作し、その背後にある関連性の理由を理解することができます。さらに、作成した図は、共有やプレゼンテーションの資料作成に利用することも可能です。

## 🎯目的: 
全ての事象には何らかのつながりがあり、その可視化は事象を理解するための重要な要素です。ビジネス、人間関係、科学、歴史などのさまざまな領域で事象の相互作用や関連性を把握することで、より深い理解につながります。

## 👥ターゲット: 
知識欲のある全ての人が対象です。科学的な観点からアプローチしたい人は、関係図から論理的なつながり、因果関係を探究するのに役に立ちます。また、文学や芸術に熱心な人には、メタフォリックなつながりや感情的なつながりから新たなアイディアを見つけることができるでしょう。



## ⚙️主要機能:

1. **入力されたデータの関連の可視化**: ユーザーが入力したデータやキーワードに基づいて関連性のあるエンティティを探し出し、それらの関連性をグラフィカルに可視化します。
2. **インタラクティブな操作**: ユーザーは関連図のノードやエッジの追加、削除、編集を直感的に行うことができます。
3. **ドメインやサービスの自動判別と分類**: 入力されたデータに基づいて、それがどのドメインやサービスに関連しているのかを自動的に判別し、適切に分類します。
4. **機械学習モデルを利用した関連の抽出**: TensorFlowやKerasなどの機械学習ライブラリを活用して、テキストからエンティティとその関連性を抽出します。
5. **共有機能**: ユーザーが作成した関連図は簡単に共有することができ、他のユーザーやチームとのコラボレーションを促進します。
6. **リアルタイムアップデート**: ユーザーが作成した関連図は、新しい情報が利用可能になるとリアルタイムで更新されます。
7. **パーソナライズされたアラート**: ユーザーが特定のトピックやキーワードについて新しい関連性が見つかったときに通知を受け取ることができます。
8. **AIを活用した関連性の発見:**: GPTや他のML技術を活用して、テキスト中に暗黙的に存在する関連性を発見し、ユーザーに新たな視点や洞察を提供します。
9. **ソーシャルメディアの統合**: ユーザーが作成した関連図を直接ソーシャルメディアに共有できます。
10. **アクセシビリティ機能**: 色覚異常や視覚障害を持つユーザーでも利用できるよう、色の選択、コントラスト、フォントサイズなどの調整が可能なアクセシビリティ設定を提供します。

##  🖥️バックエンド開発環境:
- NLPライブラリ: spaCyとGINZA
- マシンラーニングライブラリ: TensorFlow、Keras
- マシンラーニングモデル: TransformerベースのGPT

##  🌐フロントエンド開発環境:

- ライブラリ: React.js
- 3D描画ライブラリ: Three.js
- プログラミング言語: TypeScript

##  💾データベース:

- データベース管理システム: DynamoDB（ユーザーデータやその他の非グラフ型データを保存するため）
- グラフデータベース: Neo4j（エンティティ間の関連性を保存およびクエリするため

## 🧠開発ツールおよびサービス:

- 検索エンジン: Elasticsearch
- データ可視化ツール: Kibana
- バージョン管理: Git
- コンテナ化: Docker

##  ☁️インフラストラクチャおよびデプロイメント:

- サーバーレスコンピューティングサービス: AWS Lambda
- クラウドサービス: AWS

## 🔄API: 
- APIの設計とクエリ言語: GraphQL

## ♿プロジェクト管理ツール:
- Jira Confluence

## 🤖アプリの挙動: 
以下に、アプリケーションのシステムのフローチャートを示します。この図は、ユーザーからの検索クエリがシステムを通過し、最終的に視覚的なデータとしてユーザーに表示されるまでのプロセスを示しています。

![Diagram](https://showme.redstarplugin.com/s/4Je5c092)


以下に、各ステップの詳細と提案された改善点を説明します：

1. **ユーザーインタラクション**: ユーザーがアプリケーションで何かを検索すると、そのリクエストはGraphQL APIを経由してバックエンドに送信されます。これにより、クライアントは必要なデータのみを指定してリクエストでき、サーバーの負荷を減らすことができます。ユーザビリティを改善するために、このインターフェースはシンプルで直感的なものにする必要があります。

2. **データの取得と解析**: AWS Lambdaが指定されたウェブページをクロールします。次に、spaCyとGINZAを使用してテキストからエンティティとその関係性を抽出します。このプロセスは、パフォーマンスを向上させるために最適化され、非同期処理を活用する必要があります。

3. **データの保存とインデックス化**: 抽出した情報はNeo4jとDynamoDBに保存されます。同時に、Elasticsearchは新たに抽出した情報をインデックス化し、素早い検索を可能にします。

4. **データの検索と取得**: ユーザーが特定のエンティティや関係性を探すと、GraphQL APIは適切な検索クエリをElasticsearchに送信します。Elasticsearchはその結果を返し、それがユーザーに表示されます。

5. **関係図の生成**: Three.jsとReact.jsを使用して、ユーザーに対してエンティティ間の関係図を動的に描画します。この処理はクライアント側で行われ、TypeScriptを使用してロジックが記述されます。これにより、サーバーの負荷を軽減し、ユーザーエクスペリエンスを向上させます。

6. **マシンラーニングによる予測**: TensorFlowとKerasを使用して、エンティティ間の新たな関係性を予測します。これらの予測はデータベースに保存され、ユーザーが検索したときに結果として表示されます。

7. **フィードバックと改善**: ユーザーからのフィードバックはDynamoDBに保存され、システムの改善に使用されます。また、新たにクロールされたデータは定期的にSpacyに送られ、エンティティと関係性の抽出が行われます。

8. **モニタリング**: Elasticsearchの動作はKibanaでモニタリングされ、問題が発生した場合にはすぐに対応できるようにします。

9. **共有**: ユーザーは検索結果をソーシャルメディアで共有することができます。これにより、アプリケーションの認知度を高めることができます。


## 🏷️完成ロードマップ: 

### 週1-週2: プロジェクト計画と準備

- プロジェクトの要件定義とスコープの洗い出し
- 技術スタックの確認とセットアップ
- 開発環境の構築とテスト
- プロジェクトのマイルストーンとタスクの定義

### 週3-週4: バックエンドの基本構造の開発

- データの収集と解析のためのAWS Lambda関数の開発
- SpacyとGINZAを使ったNLP機能の開発
- Neo4jとDynamoDBを使ったデータの保存と管理システムの開発
- Elasticsearchを使ったデータのインデックス化と検索機能の開発
- GraphQL APIの設計と開発

### 週5-週6: フロントエンドの基本構造の開発

-  Three.jsとReact.jsを使った可視化ツールの開発
- ユーザーインタフェースとエクスペリエンスの設計と開発
- サーバーからクライアントへのデータの結合と表示

### 週7-週8: マシンラーニングの開発と統合

- TensorFlowとKerasを用いた予測モデルの開発とトレーニング
- GPTを用いたテキスト生成の開発
- マシンラーニングモデルをバックエンドとフロントエンドに統合

### 週9: アプリケーションのテストと修正

- ユニットテスト、統合テスト、エンドツーエンドテストの実行
- バグ修正とパフォーマンスの最適化
- ユーザビリティテストの実施とフィードバックの収集

### 週10: デプロイメントとドキュメンテーション

- アプリケーションのデプロイとパフォーマンスの監視
- ドキュメンテーションの作成とアップデート
- 最終的なテストとフィードバックの収集

### 週11: フィードバックのレビューと最終的な調整
